{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0a1019-225a-40b6-b73a-3186471ef58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # Importing the NumPy library for numerical operations\n",
    "import os  # Importing the OS library for interacting with the operating system\n",
    "import imageio  # Importing the imageio library for reading and writing image data\n",
    "from skimage.transform import resize  # Importing the resize function from skimage.transform for resizing images\n",
    "import datetime  # Importing the datetime module to work with date and time\n",
    "import warnings  # Importing the warnings module to manage warnings\n",
    "warnings.filterwarnings(\"ignore\")  # Ignoring all warnings\n",
    "import abc  # Importing the abc module for abstract base classes\n",
    "from sys import getsizeof  # Importing getsizeof from sys module to get the size of an object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2bde3d-a2f0-411b-9931-d97c1ff2ba51",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(30)  # Setting the seed for NumPy's random number generator for reproducibility\n",
    "import random as rn  # Importing the random library and aliasing it as rn\n",
    "rn.seed(30)  # Setting the seed for Python's random number generator for reproducibility\n",
    "from keras import backend as K  # Importing the backend module from Keras and aliasing it as K\n",
    "import tensorflow as tf  # Importing TensorFlow and aliasing it as tf\n",
    "tf.random.set_seed(30)  # Setting the seed for TensorFlow's random number generator for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5a9187-607f-4034-9d9c-16799dd1ddba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  # Importing the OpenCV library for computer vision tasks\n",
    "import matplotlib.pyplot as plt  # Importing Matplotlib's pyplot module for plotting and aliasing it as plt\n",
    "#%matplotlib inline  # Ensuring that Matplotlib plots are displayed inline within Jupyter notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d345d6ae-ce56-4111-9c65-3648ff2d2f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model  # Importing the Sequential and Model classes from Keras for building models\n",
    "from keras.layers import Dense, GRU, Flatten, TimeDistributed, BatchNormalization, Activation  # Importing various layers from Keras\n",
    "from keras.layers import Conv3D, MaxPooling3D, Conv2D, MaxPooling2D  # Importing convolutional and pooling layers for 2D and 3D data\n",
    "from keras.layers import LSTM  # Importing the LSTM layer for recurrent neural networks\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping  # Importing callback functions for training\n",
    "# from keras import optimizers  # Commented out import statement for Keras optimizers\n",
    "from tensorflow.keras import optimizers  # Importing optimizers from TensorFlow's Keras\n",
    "from keras.layers import Dropout  # Importing the Dropout layer for regularizatio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f8de32-8858-4946-bbe5-83d389d6f309",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(history):\n",
    "    # Function to plot the training and validation loss and accuracy\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 4))  # Creating a figure with 2 subplots side by side\n",
    "    axes[0].plot(history.history['loss'])  # Plotting training loss on the first subplot\n",
    "    axes[0].plot(history.history['val_loss'])  # Plotting validation loss on the first subplot\n",
    "    axes[0].grid()  # Adding grid to the first subplot\n",
    "    axes[0].legend(['loss', 'val_loss'])  # Adding legend to the first subplot\n",
    "\n",
    "    axes[1].plot(history.history['categorical_accuracy'])  # Plotting training accuracy on the second subplot\n",
    "    axes[1].plot(history.history['val_categorical_accuracy'])  # Plotting validation accuracy on the second subplot\n",
    "    axes[1].grid()  # Adding grid to the second subplot\n",
    "    axes[1].legend(['categorical_accuracy', 'val_categorical_accuracy'])  # Adding legend to the second subplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbf882b-8e3b-4da3-8600-3dff9796afc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelBuilder(metaclass=abc.ABCMeta):\n",
    "    # Method to initialize paths where project data resides\n",
    "    def initialize_path(self, project_folder):\n",
    "        self.train_doc = np.random.permutation(open(project_folder + '/' + 'train.csv').readlines())  # Shuffle training data\n",
    "        self.val_doc = np.random.permutation(open(project_folder + '/' + 'val.csv').readlines())  # Shuffle validation data\n",
    "        self.train_path = project_folder + '/' + 'train'  # Path to training data\n",
    "        self.val_path = project_folder + '/' + 'val'  # Path to validation data\n",
    "        self.num_train_sequences = len(self.train_doc)  # Number of training sequences\n",
    "        self.num_val_sequences = len(self.val_doc)  # Number of validation sequences\n",
    "\n",
    "    # Method to initialize image properties\n",
    "    def initialize_image_properties(self, image_height=100, image_width=100):\n",
    "        self.image_height = image_height  # Height of the image\n",
    "        self.image_width = image_width  # Width of the image\n",
    "        self.channels = 3  # Number of image channels (RGB)\n",
    "        self.num_classes = 5  # Number of classes for classification\n",
    "        self.total_frames = 30  # Total number of frames in each video\n",
    "\n",
    "    # Method to initialize hyperparameters: batch size, frames to sample, and number of epochs\n",
    "    def initialize_hyperparams(self, frames_to_sample=30, batch_size=20, num_epochs=20):\n",
    "        self.frames_to_sample = frames_to_sample  # Number of frames to sample from each video\n",
    "        self.batch_size = batch_size  # Batch size for training\n",
    "        self.num_epochs = num_epochs  # Number of epochs for training\n",
    "\n",
    "    # Generator function to yield batches of data\n",
    "    def generator(self, source_path, folder_list, augment=False):\n",
    "        img_idx = np.round(np.linspace(0, self.total_frames - 1, self.frames_to_sample)).astype(int)  # Indices of frames to sample\n",
    "        batch_size = self.batch_size  # Batch size for training\n",
    "        while True:\n",
    "            t = np.random.permutation(folder_list)  # Shuffle folder list\n",
    "            num_batches = len(t) // batch_size  # Number of batches per epoch\n",
    "\n",
    "            for batch in range(num_batches):\n",
    "                batch_data, batch_labels = self.one_batch_data(source_path, t, batch, batch_size, img_idx, augment)  # Get one batch of data\n",
    "                yield batch_data, batch_labels  # Yield batch data and labels\n",
    "\n",
    "            remaining_seq = len(t) % batch_size  # Remaining sequences if not divisible by batch size\n",
    "\n",
    "            if remaining_seq != 0:\n",
    "                batch_data, batch_labels = self.one_batch_data(source_path, t, num_batches, batch_size, img_idx, augment, remaining_seq)  # Get remaining sequences\n",
    "                yield batch_data, batch_labels  # Yield remaining batch data and labels\n",
    "\n",
    "    # Method to get data for one batch\n",
    "    def one_batch_data(self, source_path, t, batch, batch_size, img_idx, augment, remaining_seq=0):\n",
    "        seq_len = remaining_seq if remaining_seq else batch_size  # Length of the sequence (batch size or remaining sequences)\n",
    "\n",
    "        batch_data = np.zeros((seq_len, len(img_idx), self.image_height, self.image_width, self.channels))  # Initialize batch data array\n",
    "        batch_labels = np.zeros((seq_len, self.num_classes))  # Initialize batch labels array\n",
    "\n",
    "        if augment:\n",
    "            batch_data_aug = np.zeros((seq_len, len(img_idx), self.image_height, self.image_width, self.channels))  # Initialize augmented data array\n",
    "\n",
    "        for folder in range(seq_len):\n",
    "            imgs = os.listdir(source_path + '/' + t[folder + (batch * batch_size)].split(';')[0])  # List of images in the folder\n",
    "            for idx, item in enumerate(img_idx):\n",
    "                # Reading and resizing the image\n",
    "                image = imageio.imread(source_path + '/' + t[folder + (batch * batch_size)].strip().split(';')[0] + '/' + imgs[item]).astype(np.float32)\n",
    "                image_resized = resize(image, (self.image_height, self.image_width, 3))\n",
    "\n",
    "                # Normalizing the images\n",
    "                batch_data[folder, idx, :, :, 0] = (image_resized[:, :, 0]) / 255\n",
    "                batch_data[folder, idx, :, :, 1] = (image_resized[:, :, 1]) / 255\n",
    "                batch_data[folder, idx, :, :, 2] = (image_resized[:, :, 2]) / 255\n",
    "\n",
    "                if augment:\n",
    "                    # Applying random shifts to the image\n",
    "                    shifted = cv2.warpAffine(image,\n",
    "                                             np.float32([[1, 0, np.random.randint(-30, 30)], [0, 1, np.random.randint(-30, 30)]]),\n",
    "                                             (image.shape[1], image.shape[0]))\n",
    "\n",
    "                    gray = cv2.cvtColor(shifted, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
    "\n",
    "                    x0, y0 = np.argwhere(gray > 0).min(axis=0)\n",
    "                    x1, y1 = np.argwhere(gray > 0).max(axis=0)\n",
    "                    # Cropping the images to target gestures and remove noise\n",
    "                    cropped = shifted[x0:x1, y0:y1, :]\n",
    "\n",
    "                    image_resized = resize(cropped, (self.image_height, self.image_width, 3))\n",
    "\n",
    "                    # Normalizing the augmented images\n",
    "                    batch_data_aug[folder, idx, :, :, 0] = (image_resized[:, :, 0]) / 255\n",
    "                    batch_data_aug[folder, idx, :, :, 1] = (image_resized[:, :, 1]) / 255\n",
    "                    batch_data_aug[folder, idx, :, :, 2] = (image_resized[:, :, 2]) / 255\n",
    "\n",
    "            batch_labels[folder, int(t[folder + (batch * batch_size)].strip().split(';')[2])] = 1  # One-hot encoding the labels\n",
    "\n",
    "        if augment:\n",
    "            batch_data = np.concatenate([batch_data, batch_data_aug])  # Concatenating original and augmented data\n",
    "            batch_labels = np.concatenate([batch_labels, batch_labels])  # Concatenating original and augmented labels\n",
    "\n",
    "        return batch_data, batch_labels  # Returning batch data and labels\n",
    "\n",
    "    # Method to train the model\n",
    "    def train_model(self, model, augment_data=False):\n",
    "        train_generator = self.generator(self.train_path, self.train_doc, augment=augment_data)  # Training data generator\n",
    "        val_generator = self.generator(self.val_path, self.val_doc)  # Validation data generator\n",
    "\n",
    "        model_name = 'model_init' + '_' + str(datetime.datetime.now()).replace(' ', '').replace(':', '_') + '/'  # Model name with timestamp\n",
    "\n",
    "        if not os.path.exists(model_name):\n",
    "            os.mkdir(model_name)  # Create directory for saving the model\n",
    "\n",
    "        filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.keras'  # Filepath for saving the model\n",
    "        # As per the req saving files in .h5 format\n",
    "      #  filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'  # Filepath for saving the model\n",
    "\n",
    "        # Callbacks for saving the best model and reducing learning rate on plateau\n",
    "        checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto')\n",
    "        LR = ReduceLROnPlateau(monitor='val_loss', factor=0.2, verbose=1, patience=4)\n",
    "\n",
    "        # earlystop = EarlyStopping( monitor=\"val_loss\", min_delta=0, patience=10, verbose=1)\n",
    "        # callbacks_list = [checkpoint, LR, earlystop]\n",
    "        callbacks_list = [checkpoint, LR]  # List of callbacks\n",
    "\n",
    "        if (self.num_train_sequences % self.batch_size) == 0:\n",
    "            steps_per_epoch = int(self.num_train_sequences / self.batch_size)  # Calculate steps per epoch\n",
    "        else:\n",
    "            steps_per_epoch = (self.num_train_sequences // self.batch_size) + 1\n",
    "\n",
    "        if (self.num_val_sequences % self.batch_size) == 0:\n",
    "            validation_steps = int(self.num_val_sequences / self.batch_size)  # Calculate validation steps\n",
    "        else:\n",
    "            validation_steps = (self.num_val_sequences // self.batch_size) + 1\n",
    "\n",
    "        history = model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=self.num_epochs, verbose=1,\n",
    "                            callbacks=callbacks_list, validation_data=val_generator,\n",
    "                            validation_steps=validation_steps, class_weight=None, initial_epoch=0)  # Train the model\n",
    "        return history  # Return training history\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def define_model(self):\n",
    "        pass  # Abstract method to define the model architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78dcb455-92f0-4509-ab96-5144b6b9a19f",
   "metadata": {},
   "source": [
    "# ModelBuilder Class Explanation\n",
    "\n",
    "The **`ModelBuilder`** class is a base class for building deep learning models, especially for tasks like gesture recognition and video classification. It provides methods to initialize paths, image properties, hyperparameters, data generators, and model training procedures. Below is a detailed explanation of each part of the code:\n",
    "\n",
    "---\n",
    "\n",
    "### **Methods and Their Purposes**\n",
    "\n",
    "1. **`initialize_path`**:\n",
    "   - Sets up paths for training and validation data.\n",
    "   - Shuffles the training and validation data (`train.csv` and `val.csv`).\n",
    "   - Initializes the number of training and validation sequences.\n",
    "\n",
    "2. **`initialize_image_properties`**:\n",
    "   - Sets image height, width, and number of channels (default: RGB).\n",
    "   - Specifies the number of classes (`num_classes`) and total frames in each video (`total_frames`).\n",
    "\n",
    "3. **`initialize_hyperparams`**:\n",
    "   - Configures key training parameters:\n",
    "     - `frames_to_sample`: Number of frames to sample from each video.\n",
    "     - `batch_size`: Size of each training/validation batch.\n",
    "     - `num_epochs`: Total epochs for training.\n",
    "\n",
    "4. **`generator`**:\n",
    "   - Implements a generator to yield batches of data for training and validation.\n",
    "   - Handles data shuffling and ensures efficient memory usage by generating batches on the fly.\n",
    "   - Supports data augmentation when `augment=True`.\n",
    "\n",
    "5. **`one_batch_data`**:\n",
    "   - Extracts data for a single batch:\n",
    "     - Reads images from the specified paths.\n",
    "     - Resizes and normalizes images for model input.\n",
    "     - Supports data augmentation with random shifts, cropping, and grayscale conversion.\n",
    "   - Implements one-hot encoding for labels.\n",
    "   - Handles cases where the number of sequences is not divisible by the batch size.\n",
    "\n",
    "6. **`train_model`**:\n",
    "   - Trains the model using the provided generator:\n",
    "     - Sets up callbacks, including:\n",
    "       - **`ModelCheckpoint`**: Saves the best model during training.\n",
    "       - **`ReduceLROnPlateau`**: Reduces the learning rate when the validation loss plateaus.\n",
    "     - Dynamically calculates `steps_per_epoch` and `validation_steps` based on the number of sequences and batch size.\n",
    "   - Returns the training history for performance analysis.\n",
    "\n",
    "7. **`define_model`**:\n",
    "   - Abstract method to be implemented by subclasses to define the specific model architecture.\n",
    "\n",
    "---\n",
    "\n",
    "### **Notable Features**\n",
    "\n",
    "1. **Dynamic Generators**:\n",
    "   - Efficiently loads data in batches, avoiding memory issues for large datasets.\n",
    "   - Augmentation enhances model generalization.\n",
    "\n",
    "2. **Callbacks**:\n",
    "   - **`ModelCheckpoint`**: Saves models during training to avoid loss of progress.\n",
    "   - **`ReduceLROnPlateau`**: Adjusts learning rate dynamically to improve convergence.\n",
    "\n",
    "3. **Data Preprocessing**:\n",
    "   - Normalizes pixel values to [0, 1].\n",
    "   - Supports augmentation techniques like random shifts and cropping.\n",
    "\n",
    "4. **Flexible Architecture**:\n",
    "   - Abstract `define_model` method allows subclasses to define various neural network architectures.\n",
    "\n",
    "---\n",
    "\n",
    "### **Use Case**\n",
    "This class is highly modular and reusable for video-related machine learning tasks. By subclassing and implementing the `define_model` method, developers can quickly build and train custom models with different architectures like CNNs, RNNs, or transfer learning-based models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0acee85-87e5-408c-bdff-ab327f49e58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelConv3D1(ModelBuilder):\n",
    "\n",
    "    def define_model(self):\n",
    "        # Define the 3D convolutional neural network model\n",
    "\n",
    "        model = Sequential()  # Initialize the model as a sequential model\n",
    "\n",
    "        # First 3D convolutional layer\n",
    "        model.add(Conv3D(16, (3, 3, 3), padding='same', input_shape=(self.frames_to_sample, self.image_height, self.image_width, self.channels)))\n",
    "        model.add(Activation('relu'))  # ReLU activation\n",
    "        model.add(BatchNormalization())  # Batch normalization\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))  # Max pooling\n",
    "\n",
    "        # Second 3D convolutional layer\n",
    "        model.add(Conv3D(32, (2, 2, 2), padding='same'))\n",
    "        model.add(Activation('relu'))  # ReLU activation\n",
    "        model.add(BatchNormalization())  # Batch normalization\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))  # Max pooling\n",
    "\n",
    "        # Third 3D convolutional layer\n",
    "        model.add(Conv3D(64, (2, 2, 2), padding='same'))\n",
    "        model.add(Activation('relu'))  # ReLU activation\n",
    "        model.add(BatchNormalization())  # Batch normalization\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))  # Max pooling\n",
    "\n",
    "        # Fourth 3D convolutional layer\n",
    "        model.add(Conv3D(128, (2, 2, 2), padding='same'))\n",
    "        model.add(Activation('relu'))  # ReLU activation\n",
    "        model.add(BatchNormalization())  # Batch normalization\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))  # Max pooling\n",
    "\n",
    "        model.add(Flatten())  # Flatten the output from the convolutional layers\n",
    "\n",
    "        # First dense (fully connected) layer\n",
    "        model.add(Dense(128, activation='relu'))  # Dense layer with ReLU activation\n",
    "        model.add(BatchNormalization())  # Batch normalization\n",
    "        model.add(Dropout(0.5))  # Dropout for regularization\n",
    "\n",
    "        # Second dense (fully connected) layer\n",
    "        model.add(Dense(64, activation='relu'))  # Dense layer with ReLU activation\n",
    "        model.add(BatchNormalization())  # Batch normalization\n",
    "        model.add(Dropout(0.25))  # Dropout for regularization\n",
    "\n",
    "        # Output layer\n",
    "        model.add(Dense(self.num_classes, activation='softmax'))  # Output layer with softmax activation\n",
    "\n",
    "        optimiser = optimizers.Adam()  # Using Adam optimizer\n",
    "        # optimiser = 'sgd'  # Alternative optimizer (commented out)\n",
    "\n",
    "        # Compile the model\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "        return model  # Return the compiled model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77387290-66aa-45f2-9abb-3dc1c9161f02",
   "metadata": {},
   "source": [
    "# ModelConv3D1 Class Explanation\n",
    "\n",
    "The **`ModelConv3D1`** class is a subclass of the `ModelBuilder` base class. It defines a 3D Convolutional Neural Network (CNN) architecture for tasks involving spatiotemporal data, such as video classification. Below is a detailed explanation of the code:\n",
    "\n",
    "---\n",
    "\n",
    "### **Model Architecture**\n",
    "\n",
    "1. **Initialization**:\n",
    "   - The model is initialized as a **`Sequential`** model, allowing layers to be stacked sequentially.\n",
    "\n",
    "2. **Convolutional Layers**:\n",
    "   - The model includes four 3D convolutional layers (`Conv3D`) to capture spatial and temporal features:\n",
    "     - **Input Shape**: `(frames_to_sample, image_height, image_width, channels)`.\n",
    "     - **Filters**:\n",
    "       - 16 filters in the first layer.\n",
    "       - 32 filters in the second layer.\n",
    "       - 64 filters in the third layer.\n",
    "       - 128 filters in the fourth layer.\n",
    "     - **Kernel Size**: `(3, 3, 3)` for the first layer, and `(2, 2, 2)` for subsequent layers.\n",
    "     - **Padding**: `'same'` ensures the output dimensions remain the same after convolution.\n",
    "\n",
    "3. **Activation and Normalization**:\n",
    "   - **Activation**: Each convolutional layer uses the ReLU activation function to introduce non-linearity.\n",
    "   - **BatchNormalization**: Normalizes the activations of each layer, speeding up convergence and improving stability.\n",
    "\n",
    "4. **Pooling Layers**:\n",
    "   - Each convolutional block is followed by a **MaxPooling3D** layer with a pool size of `(2, 2, 2)`, reducing the spatial and temporal dimensions to extract prominent features.\n",
    "\n",
    "5. **Flatten Layer**:\n",
    "   - The 3D outputs from the convolutional layers are flattened into a 1D vector for input into the fully connected layers.\n",
    "\n",
    "6. **Dense Layers**:\n",
    "   - The dense layers act as fully connected layers to learn high-level representations:\n",
    "     - **First Dense Layer**:\n",
    "       - 128 neurons.\n",
    "       - ReLU activation, batch normalization, and 50% dropout.\n",
    "     - **Second Dense Layer**:\n",
    "       - 64 neurons.\n",
    "       - ReLU activation, batch normalization, and 25% dropout.\n",
    "\n",
    "7. **Output Layer**:\n",
    "   - A final dense layer with `num_classes` neurons and **softmax activation** for multi-class classification.\n",
    "\n",
    "---\n",
    "\n",
    "### **Optimizer and Compilation**\n",
    "\n",
    "- **Optimizer**: Adam optimizer is used for its adaptive learning rate and faster convergence.\n",
    "- **Loss Function**: Categorical crossentropy is chosen for multi-class classification tasks.\n",
    "- **Metrics**: The model tracks `categorical_accuracy` to evaluate performance during training and validation.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Features**\n",
    "\n",
    "1. **3D Convolutions**:\n",
    "   - Captures both spatial and temporal patterns in videos.\n",
    "\n",
    "2. **Regularization**:\n",
    "   - Dropout layers prevent overfitting.\n",
    "   - Batch normalization improves training stability.\n",
    "\n",
    "3. **Flexible Architecture**:\n",
    "   - Designed to handle input videos with multiple frames and RGB channels.\n",
    "\n",
    "4. **Modularity**:\n",
    "   - The method can be easily reused and adapted by overriding the `define_model` method.\n",
    "\n",
    "---\n",
    "\n",
    "### **Use Case**\n",
    "This model is ideal for video classification tasks where both spatial and temporal information are crucial, such as gesture recognition, action detection, and video tagging.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c107f8-6824-4e43-ade2-34bcaeaebb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_3d1 = ModelConv3D1()  # Instantiate the ModelConv3D1 class\n",
    "\n",
    "conv_3d1.initialize_path(project_folder)  # Initialize paths where project data resides\n",
    "conv_3d1.initialize_image_properties(image_height=160, image_width=160)  # Initialize image properties with specified height and width\n",
    "conv_3d1.initialize_hyperparams(frames_to_sample=30, batch_size=10, num_epochs=1)  # Initialize hyperparameters with specified values\n",
    "\n",
    "conv_3d1_model = conv_3d1.define_model()  # Define the model using the method from ModelConv3D1 class\n",
    "conv_3d1_model.summary()  # Print the summary of the model architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f725c3f0-1f7e-4b6f-95b7-f62298ab626e",
   "metadata": {},
   "source": [
    "# Explanation of the Code: Initializing and Summarizing ModelConv3D1\n",
    "\n",
    "This code demonstrates the process of initializing a 3D CNN model (`ModelConv3D1`) and verifying its architecture by printing a summary. Below is a step-by-step explanation of the code:\n",
    "\n",
    "---\n",
    "\n",
    "### **Step-by-Step Explanation**\n",
    "\n",
    "1. **Instantiate the `ModelConv3D1` Class**:\n",
    "   ```python\n",
    "   conv_3d1 = ModelConv3D1()\n",
    "- Creates an object of the ModelConv3D1 class.\n",
    "This object provides methods for setting up data paths, initializing image\n",
    "- properties, defining hyperparameters, and building a 3D convolutional neural network model.\n",
    "- 2.**Initialize Data Paths:**\n",
    "conv_3d1.initialize_path(project_folder)\n",
    "- Configures paths to the dataset.\n",
    "- **Parameter:**\n",
    "- 'project_folder:' Directory containing the project data (e.g., training and validation datasets in CSV and folder formats).\n",
    "3.**Set Image Properties:**\n",
    "conv_3d1.initialize_image_properties(image_height=160, image_width=160)\n",
    "- Specifies the height and width of input images.\n",
    "- **Parameters:**\n",
    "- 'image_height:' The height of the resized input images (160 pixels).\n",
    "- 'image_width:' The width of the resized input images (160 pixels).\n",
    "- Ensures all images have consistent dimensions before being fed into the model.\n",
    "4.**Initialize Hyperparameters:**\n",
    "- conv_3d1.initialize_hyperparams(frames_to_sample=30, batch_size=10, num_epochs=1)\n",
    "  \n",
    "**Parameters:**\n",
    "- frames_to_sample: Number of frames to sample from each video (30 frames).\n",
    "- batch_size: Number of samples processed in each batch during training (10 samples).\n",
    "- num_epochs: Number of times the model will iterate over the entire dataset (1 epoch).\n",
    "\n",
    "5.**Define the Model:**\n",
    "conv_3d1_model = conv_3d1.define_model()\n",
    "- Calls the define_model method to build the 3D CNN architecture.\n",
    "Includes layers like:\n",
    "- Conv3D for extracting spatiotemporal features.\n",
    "- MaxPooling3D for down-sampling the spatial dimensions.\n",
    "- Fully connected layers for classification.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8985edc1-e1ed-4480-b61a-5ad1d58fefe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = ModelConv3D1()  # Instantiate the ModelConv3D1 class for testing the generator\n",
    "\n",
    "test_generator.initialize_path(project_folder)  # Initialize paths where project data resides\n",
    "test_generator.initialize_image_properties(image_height=160, image_width=160)  # Initialize image properties with specified height and width\n",
    "test_generator.initialize_hyperparams(frames_to_sample=30, batch_size=3, num_epochs=1)  # Initialize hyperparameters with specified values\n",
    "\n",
    "g = test_generator.generator(test_generator.val_path, test_generator.val_doc, augment=True)  # Create a generator for validation data with augmentation\n",
    "batch_data, batch_labels = next(g)  # Generate one batch of data and labels\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2)  # Create a figure with 2 subplots side by side\n",
    "axes[0].imshow(batch_data[0, 15, :, :, :])  # Display the 16th frame of the first sample in the batch\n",
    "axes[1].imshow(batch_data[3, 15, :, :, :])  # Display the 16th frame of the fourth sample in the batch\n",
    "plt.show()  # Show the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102730f2-de82-4c3b-9e4c-58602ed7f03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_3d1.train_model(conv_3d1_model)  # Train the model using the train_model method from the ModelConv3D1 class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd00a94-eb3d-49b9-85fa-27080441ac2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_3d1 = ModelConv3D1()  # Instantiate the ModelConv3D1 class\n",
    "\n",
    "conv_3d1.initialize_path(project_folder)  # Initialize paths where project data resides\n",
    "conv_3d1.initialize_image_properties(image_height=100, image_width=100)  # Initialize image properties with specified height and width\n",
    "conv_3d1.initialize_hyperparams(frames_to_sample=30, batch_size=20, num_epochs=2)  # Initialize hyperparameters with specified values\n",
    "\n",
    "conv_3d1_model = conv_3d1.define_model()  # Define the model using the method from ModelConv3D1 class\n",
    "\n",
    "print(\"Total Params:\", conv_3d1_model.count_params())  # Print the total number of parameters in the model\n",
    "\n",
    "conv_3d1.train_model(conv_3d1_model)  # Train the model using the train_model method from the ModelConv3D1 class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae24b16d-9f28-479f-9824-313ee585bd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_3d1 = ModelConv3D1()  # Instantiate the ModelConv3D1 class\n",
    "\n",
    "conv_3d1.initialize_path(project_folder)  # Initialize paths where project data resides\n",
    "conv_3d1.initialize_image_properties(image_height=100, image_width=100)  # Initialize image properties with specified height and width\n",
    "conv_3d1.initialize_hyperparams(frames_to_sample=30, batch_size=20, num_epochs=2)  # Initialize hyperparameters with specified values\n",
    "\n",
    "conv_3d1_model = conv_3d1.define_model()  # Define the model using the method from ModelConv3D1 class\n",
    "\n",
    "print(\"Total Params:\", conv_3d1_model.count_params())  # Print the total number of parameters in the model\n",
    "\n",
    "conv_3d1.train_model(conv_3d1_model)  # Train the model using the train_model method from the ModelConv3D1 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0dac3a2-161b-4297-b36f-cf74a4e2adda",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelConv3D1(ModelBuilder):\n",
    "\n",
    "    def define_model(self, filtersize=(3, 3, 3), dense_neurons=64, dropout=0.25):\n",
    "        # Define the 3D convolutional neural network model with customizable parameters\n",
    "\n",
    "        model = Sequential()  # Initialize the model as a sequential model\n",
    "\n",
    "        # First 3D convolutional layer\n",
    "        model.add(Conv3D(16, filtersize, padding='same', input_shape=(self.frames_to_sample, self.image_height, self.image_width, self.channels)))\n",
    "        model.add(Activation('relu'))  # ReLU activation\n",
    "        model.add(BatchNormalization())  # Batch normalization\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))  # Max pooling\n",
    "\n",
    "        # Second 3D convolutional layer\n",
    "        model.add(Conv3D(32, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))  # ReLU activation\n",
    "        model.add(BatchNormalization())  # Batch normalization\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))  # Max pooling\n",
    "\n",
    "        # Third 3D convolutional layer\n",
    "        model.add(Conv3D(64, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))  # ReLU activation\n",
    "        model.add(BatchNormalization())  # Batch normalization\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))  # Max pooling\n",
    "\n",
    "        # Fourth 3D convolutional layer\n",
    "        model.add(Conv3D(128, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))  # ReLU activation\n",
    "        model.add(BatchNormalization())  # Batch normalization\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))  # Max pooling\n",
    "\n",
    "        model.add(Flatten())  # Flatten the output from the convolutional layers\n",
    "\n",
    "        # First dense (fully connected) layer\n",
    "        model.add(Dense(dense_neurons, activation='relu'))  # Dense layer with ReLU activation\n",
    "        model.add(BatchNormalization())  # Batch normalization\n",
    "        model.add(Dropout(dropout))  # Dropout for regularization\n",
    "\n",
    "        # Second dense (fully connected) layer\n",
    "        model.add(Dense(dense_neurons, activation='relu'))  # Dense layer with ReLU activation\n",
    "        model.add(BatchNormalization())  # Batch normalization\n",
    "        model.add(Dropout(dropout))  # Dropout for regularization\n",
    "\n",
    "        # Output layer\n",
    "        model.add(Dense(self.num_classes, activation='softmax'))  # Output layer with softmax activation\n",
    "\n",
    "        optimiser = optimizers.Adam()  # Using Adam optimizer\n",
    "\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])  # Compile the model\n",
    "\n",
    "        return model  # Return the compiled model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328cdc62-68c6-4f81-8c70-20afa5a53865",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_3d1 = ModelConv3D1()  # Instantiate the ModelConv3D1 class\n",
    "\n",
    "conv_3d1.initialize_path(project_folder)  # Initialize paths where project data resides\n",
    "conv_3d1.initialize_image_properties(image_height=160, image_width=160)  # Initialize image properties with specified height and width\n",
    "conv_3d1.initialize_hyperparams(frames_to_sample=20, batch_size=40, num_epochs=20)  # Initialize hyperparameters with specified values\n",
    "\n",
    "conv_3d1_model = conv_3d1.define_model()  # Define the model using the method from ModelConv3D1 class\n",
    "conv_3d1_model.summary()  # Print the summary of the model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d02a33-ec67-43be-8172-e7ec797c81ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the total number of parameters in the model\n",
    "print(\"Total Params:\", conv_3d1_model.count_params())\n",
    "\n",
    "# Train the model using the train_model method from the ModelConv3D1 class\n",
    "history_model1 = conv_3d1.train_model(conv_3d1_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62e3f0d-9c45-4c19-864b-b2bb78c9769d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(history_model1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9feef7c-87c3-4ba6-9945-8161d7240fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the ModelConv3D1 class\n",
    "conv_3d2 = ModelConv3D1()\n",
    "\n",
    "# Initialize paths where project data resides\n",
    "conv_3d2.initialize_path(project_folder)\n",
    "\n",
    "# Initialize image properties with specified height and width\n",
    "conv_3d2.initialize_image_properties(image_height=160, image_width=160)\n",
    "\n",
    "# Initialize hyperparameters with specified values\n",
    "conv_3d2.initialize_hyperparams(frames_to_sample=20, batch_size=20, num_epochs=25)\n",
    "\n",
    "# Define the model with customized dense layer neurons and dropout rate\n",
    "conv_3d2_model = conv_3d2.define_model(dense_neurons=256, dropout=0.5)\n",
    "\n",
    "# Print the summary of the model architecture\n",
    "conv_3d2_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee04e0ea-ff7c-4bf9-a441-801d8c972d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total Params:\", conv_3d2_model.count_params())\n",
    "history_model2=conv_3d2.train_model(conv_3d2_model,augment_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45126ff-9ae3-4254-96b3-586a14e10bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(history_model2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c26edd0-90a2-48b5-81af-cdb8e2381070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new class ModelConv3D3 inheriting from ModelBuilder\n",
    "class ModelConv3D3(ModelBuilder):\n",
    "\n",
    "    # Define a method to define the model architecture\n",
    "    def define_model(self, filtersize=(3, 3, 3), dense_neurons=64, dropout=0.25):\n",
    "\n",
    "        model = Sequential()  # Initialize a sequential model\n",
    "\n",
    "        # Add the first 3D convolutional layer with specified parameters\n",
    "        model.add(Conv3D(16, filtersize, padding='same', input_shape=(self.frames_to_sample, self.image_height, self.image_width, self.channels)))\n",
    "        model.add(Activation('relu'))  # ReLU activation function\n",
    "        model.add(BatchNormalization())  # Batch normalization\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))  # Max pooling\n",
    "\n",
    "        # Add the second 3D convolutional layer with specified parameters\n",
    "        model.add(Conv3D(32, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))  # ReLU activation function\n",
    "        model.add(BatchNormalization())  # Batch normalization\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))  # Max pooling\n",
    "\n",
    "        # Add the third 3D convolutional layer with specified parameters\n",
    "        model.add(Conv3D(64, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))  # ReLU activation function\n",
    "        model.add(BatchNormalization())  # Batch normalization\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))  # Max pooling\n",
    "\n",
    "        # Add the fourth 3D convolutional layer with specified parameters\n",
    "        model.add(Conv3D(128, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))  # ReLU activation function\n",
    "        model.add(BatchNormalization())  # Batch normalization\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))  # Max pooling\n",
    "\n",
    "        model.add(Flatten())  # Flatten the output from the convolutional layers\n",
    "\n",
    "        # Add the first dense (fully connected) layer with specified number of neurons and activation function\n",
    "        model.add(Dense(dense_neurons, activation='relu'))\n",
    "        model.add(BatchNormalization())  # Batch normalization\n",
    "        model.add(Dropout(dropout))  # Dropout for regularization\n",
    "\n",
    "        # Add the second dense (fully connected) layer with specified number of neurons and activation function\n",
    "        model.add(Dense(dense_neurons, activation='relu'))\n",
    "        model.add(BatchNormalization())  # Batch normalization\n",
    "        model.add(Dropout(dropout))  # Dropout for regularization\n",
    "\n",
    "        # Add the output layer with softmax activation function\n",
    "        model.add(Dense(self.num_classes, activation='softmax'))\n",
    "\n",
    "        # Compile the model with Adam optimizer and specified learning rate\n",
    "        optimiser = optimizers.Adam(lr=0.0002)\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "        return model  # Return the compiled model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3f0ba4-d791-4c17-ad05-6dd15e482446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the ModelConv3D3 class\n",
    "conv_3d3 = ModelConv3D3()\n",
    "\n",
    "# Initialize paths where project data resides\n",
    "conv_3d3.initialize_path(project_folder)\n",
    "\n",
    "# Initialize image properties with specified height and width\n",
    "conv_3d3.initialize_image_properties(image_height=120, image_width=120)\n",
    "\n",
    "# Initialize hyperparameters with specified values\n",
    "conv_3d3.initialize_hyperparams(frames_to_sample=16, batch_size=30, num_epochs=25)\n",
    "\n",
    "# Define the model with customized filter size, dense layer neurons, and dropout rate\n",
    "conv_3d3_model = conv_3d3.define_model(filtersize=(2, 2, 2), dense_neurons=256, dropout=0.5)\n",
    "\n",
    "# Print the summary of the model architecture\n",
    "conv_3d3_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e86a97c-2e4e-45e6-97d9-650aeff74f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total Params:\", conv_3d3_model.count_params())\n",
    "history_model3=conv_3d3.train_model(conv_3d3_model,augment_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b125002d-ecbc-4119-bcd1-eafc354046d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(history_model3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77431e23-332e-4358-94a2-0e83d9c32dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding more layers - Batch Size = 20 and No. of Epochs = 25\n",
    "# Define a new class ModelConv3D4 inheriting from ModelBuilder\n",
    "class ModelConv3D4(ModelBuilder):\n",
    "\n",
    "    # Define a method to define the model architecture\n",
    "    def define_model(self, filtersize=(3, 3, 3), dense_neurons=64, dropout=0.25):\n",
    "\n",
    "        model = Sequential()  # Initialize a sequential model\n",
    "\n",
    "        # First convolutional block\n",
    "        model.add(Conv3D(16, filtersize, padding='same', input_shape=(self.frames_to_sample, self.image_height, self.image_width, self.channels)))\n",
    "        model.add(Activation('relu'))  # ReLU activation function\n",
    "        model.add(BatchNormalization())  # Batch normalization\n",
    "\n",
    "        # Second convolutional block\n",
    "        model.add(Conv3D(16, filtersize, padding='same', input_shape=(self.frames_to_sample, self.image_height, self.image_width, self.channels)))\n",
    "        model.add(Activation('relu'))  # ReLU activation function\n",
    "        model.add(BatchNormalization())  # Batch normalization\n",
    "\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))  # Max pooling\n",
    "\n",
    "        # Third convolutional block\n",
    "        model.add(Conv3D(32, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))  # ReLU activation function\n",
    "        model.add(BatchNormalization())  # Batch normalization\n",
    "\n",
    "        # Fourth convolutional block\n",
    "        model.add(Conv3D(32, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))  # ReLU activation function\n",
    "        model.add(BatchNormalization())  # Batch normalization\n",
    "\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))  # Max pooling\n",
    "\n",
    "        # Fifth convolutional block\n",
    "        model.add(Conv3D(64, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))  # ReLU activation function\n",
    "        model.add(BatchNormalization())  # Batch normalization\n",
    "\n",
    "        # Sixth convolutional block\n",
    "        model.add(Conv3D(64, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))  # ReLU activation function\n",
    "        model.add(BatchNormalization())  # Batch normalization\n",
    "\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))  # Max pooling\n",
    "\n",
    "        # Seventh convolutional block\n",
    "        model.add(Conv3D(128, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))  # ReLU activation function\n",
    "        model.add(BatchNormalization())  # Batch normalization\n",
    "\n",
    "        # Eighth convolutional block\n",
    "        model.add(Conv3D(128, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))  # ReLU activation function\n",
    "        model.add(BatchNormalization())  # Batch normalization\n",
    "\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))  # Max pooling\n",
    "\n",
    "        model.add(Flatten())  # Flatten the output from the convolutional layers\n",
    "\n",
    "        # First dense (fully connected) layer\n",
    "        model.add(Dense(dense_neurons, activation='relu'))\n",
    "        model.add(BatchNormalization())  # Batch normalization\n",
    "        model.add(Dropout(dropout))  # Dropout for regularization\n",
    "\n",
    "        # Second dense (fully connected) layer\n",
    "        model.add(Dense(dense_neurons, activation='relu'))\n",
    "        model.add(BatchNormalization())  # Batch normalization\n",
    "        model.add(Dropout(dropout))  # Dropout for regularization\n",
    "\n",
    "        # Output layer with softmax activation function\n",
    "        model.add(Dense(self.num_classes, activation='softmax'))\n",
    "\n",
    "        # Compile the model with Adam optimizer and default learning rate\n",
    "        optimiser = optimizers.Adam()\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "        return model  # Return the compiled model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8e0749-1924-429f-9233-cd56d78775e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_3d4=ModelConv3D4()\n",
    "conv_3d4.initialize_path(project_folder)\n",
    "conv_3d4.initialize_image_properties(image_height=120,image_width=120)\n",
    "conv_3d4.initialize_hyperparams(frames_to_sample=16,batch_size=20,num_epochs=10)\n",
    "conv_3d4_model=conv_3d4.define_model(filtersize=(3,3,3),dense_neurons=256,dropout=0.5)\n",
    "conv_3d4_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24eaa14-2991-4dcf-852b-1af3557d6269",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total Params:\", conv_3d4_model.count_params())\n",
    "history_model4=conv_3d4.train_model(conv_3d4_model,augment_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52201ad2-6a03-4591-84c5-cea1bceae570",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(history_model4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a91d788-1de5-4e51-b329-3b01d428d795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding dropout at convolution layers\n",
    "\n",
    "# Define a new class ModelConv3D5 inheriting from ModelBuilder\n",
    "class ModelConv3D5(ModelBuilder):\n",
    "    \n",
    "    # Define a method to define the model architecture\n",
    "    def define_model(self, filtersize=(3, 3, 3), dense_neurons=64, dropout=0.25):\n",
    "\n",
    "        model = Sequential()  # Initialize a sequential model\n",
    "\n",
    "        # First convolutional block\n",
    "        model.add(Conv3D(16, filtersize, padding='same', input_shape=(self.frames_to_sample, self.image_height, self.image_width, self.channels)))\n",
    "        model.add(Activation('relu'))  # ReLU activation function\n",
    "        model.add(BatchNormalization())  # Batch normalization\n",
    "\n",
    "        # Second convolutional block\n",
    "        model.add(Conv3D(16, filtersize, padding='same', input_shape=(self.frames_to_sample, self.image_height, self.image_width, self.channels)))\n",
    "        model.add(Activation('relu'))  # ReLU activation function\n",
    "        model.add(BatchNormalization())  # Batch normalization\n",
    "\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))  # Max pooling\n",
    "        model.add(Dropout(dropout))  # Dropout for regularization\n",
    "\n",
    "        # Third convolutional block\n",
    "        model.add(Conv3D(32, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))  # ReLU activation function\n",
    "        model.add(BatchNormalization())  # Batch normalization\n",
    "\n",
    "        # Fourth convolutional block\n",
    "        model.add(Conv3D(32, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))  # ReLU activation function\n",
    "        model.add(BatchNormalization())  # Batch normalization\n",
    "\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))  # Max pooling\n",
    "        model.add(Dropout(dropout))  # Dropout for regularization\n",
    "\n",
    "        # Fifth convolutional block\n",
    "        model.add(Conv3D(64, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))  # ReLU activation function\n",
    "        model.add(BatchNormalization())  # Batch normalization\n",
    "\n",
    "        # Sixth convolutional block\n",
    "        model.add(Conv3D(64, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))  # ReLU activation function\n",
    "        model.add(BatchNormalization())  # Batch normalization\n",
    "\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))  # Max pooling\n",
    "        model.add(Dropout(dropout))  # Dropout for regularization\n",
    "\n",
    "        # Seventh convolutional block\n",
    "        model.add(Conv3D(128, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))  # ReLU activation function\n",
    "        model.add(BatchNormalization())  # Batch normalization\n",
    "\n",
    "        # Eighth convolutional block\n",
    "        model.add(Conv3D(128, filtersize, padding='same'))\n",
    "        model.add(Activation('relu'))  # ReLU activation function\n",
    "        model.add(BatchNormalization())  # Batch normalization\n",
    "\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))  # Max pooling\n",
    "        model.add(Dropout(dropout))  # Dropout for regularization\n",
    "\n",
    "        model.add(Flatten())  # Flatten the output from the convolutional layers\n",
    "\n",
    "        # First dense (fully connected) layer\n",
    "        model.add(Dense(dense_neurons, activation='relu'))\n",
    "        model.add(BatchNormalization())  # Batch normalization\n",
    "        model.add(Dropout(dropout))  # Dropout for regularization\n",
    "\n",
    "        # Second dense (fully connected) layer\n",
    "        model.add(Dense(dense_neurons, activation='relu'))\n",
    "        model.add(BatchNormalization())  # Batch normalization\n",
    "        model.add(Dropout(dropout))  # Dropout for regularization\n",
    "\n",
    "        # Output layer with softmax activation function\n",
    "        model.add(Dense(self.num_classes, activation='softmax'))\n",
    "\n",
    "        # Compile the model with Adam optimizer and default learning rate\n",
    "        optimiser = optimizers.Adam()\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "        return model  # Return the compiled model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3038a85-ea9b-4451-be79-a50878c18510",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_3d5=ModelConv3D5()\n",
    "conv_3d5.initialize_path(project_folder)\n",
    "conv_3d5.initialize_image_properties(image_height=120,image_width=120)\n",
    "conv_3d5.initialize_hyperparams(frames_to_sample=16,batch_size=20,num_epochs=15)\n",
    "conv_3d5_model=conv_3d5.define_model(filtersize=(3,3,3),dense_neurons=256,dropout=0.25)\n",
    "conv_3d5_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6140b6c-4887-4baf-bea1-e5032724055e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total Params:\", conv_3d5_model.count_params())\n",
    "history_model5=conv_3d5.train_model(conv_3d5_model,augment_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e39223-bdaa-451d-820b-fe60df2f2fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(history_model5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7ce9ed-fd4d-4e86-bfdb-cc5c5976010a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reducing the number of parameters\n",
    "# Define a new class ModelConv3D6 inheriting from ModelBuilder\n",
    "class ModelConv3D6(ModelBuilder):\n",
    "    \n",
    "    # Define a method to define the model architecture\n",
    "    def define_model(self, dense_neurons=64, dropout=0.25):\n",
    "\n",
    "        model = Sequential()  # Initialize a sequential model\n",
    "\n",
    "        # First convolutional block\n",
    "        model.add(Conv3D(16, (3, 3, 3), padding='same', input_shape=(self.frames_to_sample, self.image_height, self.image_width, self.channels)))\n",
    "        model.add(Activation('relu'))  # ReLU activation function\n",
    "        model.add(BatchNormalization())  # Batch normalization\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))  # Max pooling\n",
    "\n",
    "        # Second convolutional block\n",
    "        model.add(Conv3D(32, (2, 2, 2), padding='same'))\n",
    "        model.add(Activation('relu'))  # ReLU activation function\n",
    "        model.add(BatchNormalization())  # Batch normalization\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))  # Max pooling\n",
    "\n",
    "        # Third convolutional block\n",
    "        model.add(Conv3D(64, (2, 2, 2), padding='same'))\n",
    "        model.add(Activation('relu'))  # ReLU activation function\n",
    "        model.add(BatchNormalization())  # Batch normalization\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))  # Max pooling\n",
    "\n",
    "        # Fourth convolutional block\n",
    "        model.add(Conv3D(128, (2, 2, 2), padding='same'))\n",
    "        model.add(Activation('relu'))  # ReLU activation function\n",
    "        model.add(BatchNormalization())  # Batch normalization\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))  # Max pooling\n",
    "        \n",
    "        model.add(Flatten())  # Flatten the output from the convolutional layers\n",
    "\n",
    "        # First dense (fully connected) layer\n",
    "        model.add(Dense(dense_neurons, activation='relu'))\n",
    "        model.add(BatchNormalization())  # Batch normalization\n",
    "        model.add(Dropout(dropout))  # Dropout for regularization\n",
    "\n",
    "        # Second dense (fully connected) layer\n",
    "        model.add(Dense(dense_neurons, activation='relu'))\n",
    "        model.add(BatchNormalization())  # Batch normalization\n",
    "        model.add(Dropout(dropout))  # Dropout for regularization\n",
    "\n",
    "        # Output layer with softmax activation function\n",
    "        model.add(Dense(self.num_classes, activation='softmax'))\n",
    "\n",
    "        # Compile the model with Adam optimizer and a custom learning rate\n",
    "        optimiser = optimizers.Adam(lr=0.0002)\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "        return model  # Return the compiled model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a348ac-7349-4a3d-ad57-c1c0dcd11c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_3d6=ModelConv3D6()\n",
    "conv_3d6.initialize_path(project_folder)\n",
    "conv_3d6.initialize_image_properties(image_height=100,image_width=100)\n",
    "conv_3d6.initialize_hyperparams(frames_to_sample=16,batch_size=20,num_epochs=12)\n",
    "conv_3d6_model=conv_3d6.define_model(dense_neurons=128,dropout=0.25)\n",
    "conv_3d6_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d4d000-d4f6-4781-95fa-e11f882e1613",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total Params:\", conv_3d6_model.count_params())\n",
    "history_model6=conv_3d6.train_model(conv_3d6_model,augment_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a88761d-0aba-4aa1-89a7-26fa3c8dad47",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(history_model6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c895860a-499e-4225-be82-c7771216fdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 7 - Reducing the number of parameters again\n",
    "\n",
    "# Define the ModelConv3D7 class that inherits from ModelBuilder\n",
    "class ModelConv3D7(ModelBuilder):\n",
    "\n",
    "    # Define the model structure with parameters for dense layer neurons and dropout rate\n",
    "    def define_model(self, dense_neurons=64, dropout=0.25):\n",
    "\n",
    "        # Initialize a sequential model\n",
    "        model = Sequential()\n",
    "        \n",
    "        # Add the first 3D convolutional layer with 16 filters, kernel size of 3x3x3, 'same' padding\n",
    "        # and specify the input shape\n",
    "        model.add(Conv3D(16, (3, 3, 3), padding='same',\n",
    "                         input_shape=(self.frames_to_sample, self.image_height, self.image_width, self.channels)))\n",
    "        model.add(Activation('relu'))  # Add ReLU activation\n",
    "        model.add(BatchNormalization())  # Add batch normalization\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))  # Add 3D max pooling layer with pool size of 2x2x2\n",
    "\n",
    "        # Add the second 3D convolutional layer with 32 filters and kernel size of 3x3x3\n",
    "        model.add(Conv3D(32, (3, 3, 3), padding='same'))\n",
    "        model.add(Activation('relu'))  # Add ReLU activation\n",
    "        model.add(BatchNormalization())  # Add batch normalization\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))  # Add 3D max pooling layer\n",
    "\n",
    "        # Add the third 3D convolutional layer with 64 filters and kernel size of 2x2x2\n",
    "        model.add(Conv3D(64, (2, 2, 2), padding='same'))\n",
    "        model.add(Activation('relu'))  # Add ReLU activation\n",
    "        model.add(BatchNormalization())  # Add batch normalization\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))  # Add 3D max pooling layer\n",
    "\n",
    "        # Add the fourth 3D convolutional layer with 128 filters and kernel size of 2x2x2\n",
    "        model.add(Conv3D(128, (2, 2, 2), padding='same'))\n",
    "        model.add(Activation('relu'))  # Add ReLU activation\n",
    "        model.add(BatchNormalization())  # Add batch normalization\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))  # Add 3D max pooling layer\n",
    "\n",
    "        # Flatten the output from the convolutional layers to feed into fully connected layers\n",
    "        model.add(Flatten())\n",
    "        \n",
    "        # Add the first dense layer with the specified number of neurons and ReLU activation\n",
    "        model.add(Dense(dense_neurons, activation='relu'))\n",
    "        model.add(BatchNormalization())  # Add batch normalization\n",
    "        model.add(Dropout(dropout))  # Add dropout for regularization\n",
    "\n",
    "        # Add the second dense layer with the same number of neurons and ReLU activation\n",
    "        model.add(Dense(dense_neurons, activation='relu'))\n",
    "        model.add(BatchNormalization())  # Add batch normalization\n",
    "        model.add(Dropout(dropout))  # Add dropout for regularization\n",
    "\n",
    "        # Add the output layer with the number of classes and softmax activation for classification\n",
    "        model.add(Dense(self.num_classes, activation='softmax'))\n",
    "\n",
    "        # Define the optimizer and compile the model with categorical crossentropy loss and accuracy metric\n",
    "        optimiser = optimizers.Adam(lr=0.0002)\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "        # Return the compiled model\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98694695-2047-4504-a29f-ea01696ab129",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_3d7=ModelConv3D7()\n",
    "conv_3d7.initialize_path(project_folder)\n",
    "conv_3d7.initialize_image_properties(image_height=120,image_width=120)\n",
    "conv_3d7.initialize_hyperparams(frames_to_sample=16,batch_size=20,num_epochs=25)\n",
    "conv_3d7_model=conv_3d7.define_model(dense_neurons=64,dropout=0.25)\n",
    "conv_3d7_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ebce6f-cac1-4839-88f2-eba93acda4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total Params:\", conv_3d7_model.count_params())\n",
    "history_model7=conv_3d7.train_model(conv_3d7_model,augment_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d5b454-cf73-42c9-af25-ec5d1717b293",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(history_model7)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
